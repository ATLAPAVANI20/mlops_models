{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ecb931",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_DIR = 'cifar-10-batches-py/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ab4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        cifar_dict = pickle.load(fo, encoding='bytes')\n",
    "    return cifar_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a9482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['batches.meta', 'data_batch_1', 'data_batch_2', 'data_batch_3','data_batch_4', 'data_batch_5', 'test_batch']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2eabbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [0,1,2,3,4,5,6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "841afd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar-10-batches-py/\n"
     ]
    }
   ],
   "source": [
    "print(CIFAR_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b5ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,direc in zip(all_data,dirs):\n",
    "    all_data[i] = unpickle(CIFAR_DIR+direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b0f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_meta = all_data[0]\n",
    "data_batch1 = all_data[1]\n",
    "data_batch2 = all_data[2]\n",
    "data_batch3 = all_data[3]\n",
    "data_batch4 = all_data[4]\n",
    "data_batch5 = all_data[5]\n",
    "test_batch = all_data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7b1ad25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'num_cases_per_batch': 10000,\n",
       " b'label_names': [b'airplane',\n",
       "  b'automobile',\n",
       "  b'bird',\n",
       "  b'cat',\n",
       "  b'deer',\n",
       "  b'dog',\n",
       "  b'frog',\n",
       "  b'horse',\n",
       "  b'ship',\n",
       "  b'truck'],\n",
       " b'num_vis': 3072}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a83aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bdbbe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_batch1[b\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07faa23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6f6489",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X[0]/255).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dbc775",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc38bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(vec, vals=10):\n",
    "    '''\n",
    "    for use to one-hot encode the 10- possible labels\n",
    "    '''\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n, vals))\n",
    "    out[range(n), vec] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa53c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarHelper():\n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "        \n",
    "        self.all_train_batches = [data_batch1,data_batch2,data_batch3,data_batch4,data_batch5]\n",
    "        self.test_batch = [test_batch]\n",
    "        \n",
    "        self.training_images = None\n",
    "        self.training_labels = None\n",
    "        \n",
    "        self.test_images = None\n",
    "        self.test_labels = None\n",
    "    \n",
    "    def set_up_images(self):\n",
    "        \n",
    "        print(\"Setting Up Training Images and labels\")\n",
    "        \n",
    "        self.training_images = np.vstack([d[b\"data\"] for d in self.all_train_batches])\n",
    "        train_len = len(self.training_images)\n",
    "        \n",
    "        self.training_images = self.training_images.reshape(train_len,3,32,32).transpose(0,2,3,1)/255\n",
    "        self.training_labels = one_hot_encode(np.hstack([d[b\"labels\"] for d in self.all_train_batches]), 10)\n",
    "\n",
    "        \n",
    "        print(\"Setting Up Test Images and Labels\")\n",
    "        \n",
    "        self.test_images = np.vstack([d[b\"data\"] for d in self.test_batch])\n",
    "        test_len = len(self.test_images)\n",
    "        \n",
    "        self.test_images = self.test_images.reshape(test_len,3,32,32).transpose(0,2,3,1)/255\n",
    "        self.test_labels = one_hot_encode(np.hstack([d[b\"labels\"] for d in self.test_batch]), 10)\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        x = self.training_images[self.i:self.i+batch_size].reshape(100,32,32,3)\n",
    "        y = self.training_labels[self.i:self.i+batch_size]\n",
    "        self.i = (self.i + batch_size) % len(self.training_images)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4cfa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before your tf.session run these two lines\n",
    "ch = CifarHelper()\n",
    "ch.set_up_images()\n",
    "batch = ch.next_batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,32,32,3])\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,10])\n",
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e48d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                         strides=[1, 2, 2, 1], padding='SAME')\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27048c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x,shape=[4,4,3,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)\n",
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[4,4,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)\n",
    "8*8*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de932523",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1,8*8*64])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96ee54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,10)\n",
    "print(y_pred)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a1df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8aca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(500):\n",
    "        batch = ch.next_batch(100)\n",
    "        sess.run(train, feed_dict={x: batch[0], y_true:batch[1], hold_prob: 0.5})\n",
    "        #print out a message every 100 steps\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is :')\n",
    "            \n",
    "            #test the train model\n",
    "            \n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "            \n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "            \n",
    "            print(sess.run(acc,feed_dict={x:ch.test_images,y_true:ch.test_labels,hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c30603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ef119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
